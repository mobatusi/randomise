{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Add all the packages required "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": true,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "import nipype.pipeline.engine as pe\n",
    "import nipype.interfaces.fsl as fsl\n",
    "import nipype.interfaces.io as nio"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": true,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "#!/usr/bin/env python\n",
    "import argparse\n",
    "import os\n",
    "import sys\n",
    "import pandas as pd\n",
    "import patsy\n",
    "import json\n",
    "import numpy as np\n",
    "from create_flame_model_files import create_flame_model_files\n",
    "__version__ = 0.1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "###"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": true,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "working_dir = '/home/jovyan/work/test_data/'\n",
    "file_list = '/home/jovyan/work/test_data/IBA_TRT/'\n",
    "in_model_file = '/home/jovyan/work/test_data/IBA_TRT/model.json'\n",
    "in_bids_dir =  '/home/jovyan/work/test_data/IBA_TRT/'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "collapsed": true,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "# load in the model\n",
    "with open(in_model_file) as model_fd:\n",
    "     model_dict = json.load(model_fd)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "collapsed": true,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "# parse the model string to determine which columns of the pheno\n",
    "    # file we are interested in\n",
    "in_columns = model_dict[\"model\"].replace(\"-1\", \"\").replace(\"-\", \"+\").split(\"+\")\n",
    "t_columns = []\n",
    "for column in in_columns:\n",
    "    if '*' in column:\n",
    "            t_columns += column.split(\"*\")\n",
    "    else:\n",
    "            t_columns.append(column)\n",
    "    in_columns = list(set(t_columns))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "collapsed": true,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "# read in the pheno file\n",
    "pheno_df = pd.read_csv(os.path.join(in_bids_dir,'participants.tsv'), sep='\\t')\n",
    "\n",
    "# reduce the file to just the columns that we are interested in\n",
    "#heno_df = pheno_df[['participant_id'] + in_columns]\n",
    "pheno_df = pheno_df[['sub'] + in_columns]\n",
    "\n",
    "# remove rows that have empty elements\n",
    "pheno_df = pheno_df.dropna()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "file_list = "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [
    {
     "ename": "TraitError",
     "evalue": "The 'in_files' trait of a MergeInputSpec instance must be a list of items which are an existing file name, but a value of '/home/jovyan/work/test_data/IBA_TRT/' <class 'str'> was specified.",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mTraitError\u001b[0m                                Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-10-037044beb625>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      8\u001b[0m \u001b[0;31m# First merge input files into single 4D file\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      9\u001b[0m \u001b[0mmerge\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mpe\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mNode\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minterface\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mfsl\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mMerge\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mname\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m'fsl_merge'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 10\u001b[0;31m \u001b[0mmerge\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0minputs\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0min_files\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mfile_list\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     11\u001b[0m \u001b[0mmerge\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0minputs\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdimension\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m't'\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     12\u001b[0m \u001b[0mmerge_output\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m\"randomise_pipe_merge.nii.gz\"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/opt/conda/lib/python3.5/site-packages/traits/trait_types.py\u001b[0m in \u001b[0;36mvalidate\u001b[0;34m(self, object, name, value)\u001b[0m\n\u001b[1;32m   2337\u001b[0m             \u001b[0;32mreturn\u001b[0m \u001b[0mTraitListObject\u001b[0m\u001b[0;34m(\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mobject\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mname\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mvalue\u001b[0m \u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2338\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 2339\u001b[0;31m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0merror\u001b[0m\u001b[0;34m(\u001b[0m \u001b[0mobject\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mname\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mvalue\u001b[0m \u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   2340\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2341\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mfull_info\u001b[0m \u001b[0;34m(\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mobject\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mname\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mvalue\u001b[0m \u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/opt/conda/lib/python3.5/site-packages/traits/trait_handlers.py\u001b[0m in \u001b[0;36merror\u001b[0;34m(self, object, name, value)\u001b[0m\n\u001b[1;32m    171\u001b[0m         \"\"\"\n\u001b[1;32m    172\u001b[0m         raise TraitError( object, name, self.full_info( object, name, value ),\n\u001b[0;32m--> 173\u001b[0;31m                           value )\n\u001b[0m\u001b[1;32m    174\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    175\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mfull_info\u001b[0m \u001b[0;34m(\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mobject\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mname\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mvalue\u001b[0m \u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mTraitError\u001b[0m: The 'in_files' trait of a MergeInputSpec instance must be a list of items which are an existing file name, but a value of '/home/jovyan/work/test_data/IBA_TRT/' <class 'str'> was specified."
     ]
    }
   ],
   "source": [
    "import nipype.pipeline.engine as pe\n",
    "import nipype.interfaces.fsl as fsl\n",
    "import nipype.interfaces.io as nio\n",
    "\n",
    "wf = pe.Workflow(name='wf_randomize')\n",
    "wf.base_dir = working_dir\n",
    "\n",
    "# First merge input files into single 4D file\n",
    "merge = pe.Node(interface=fsl.Merge(), name='fsl_merge')\n",
    "merge.inputs.in_files = file_list\n",
    "merge.inputs.dimension = 't'\n",
    "merge_output = \"randomise_pipe_merge.nii.gz\"\n",
    "merge.inputs.merged_file = merge_output\n",
    "\n",
    "# Create a mask from the merged file\n",
    "mask = pe.Node(interface=fsl.maths.MathsCommand(), name='fsl_maths')\n",
    "mask.inputs.args = '-abs -Tmin -bin'\n",
    "merge_mask_output = \"randomise_pipe_mask.nii.gz\"\n",
    "mask.inputs.out_file = merge_mask_output\n",
    "wf.connect(merge, 'merged_file', mask, 'in_file')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'wf' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-5-9253cfe8807b>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0mrandomise\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mpe\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mNode\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minterface\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mfsl\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mRandomise\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mname\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m'fsl_randomise'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 2\u001b[0;31m \u001b[0mwf\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mconnect\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmask\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'out_file'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mrandomise\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'mask'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      3\u001b[0m \u001b[0mrandomise\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0minputs\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbase_name\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m\"randomise_pipe_contrast_{0}\"\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mformat\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mcurrent_contrast\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m \u001b[0mrandomise\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0minputs\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdesign_mat\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmat_file\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m \u001b[0mrandomise\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0minputs\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtcon\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mcon_file\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mNameError\u001b[0m: name 'wf' is not defined"
     ]
    }
   ],
   "source": [
    "randomise = pe.Node(interface=fsl.Randomise(), name='fsl_randomise')\n",
    "wf.connect(mask, 'out_file', randomise, 'mask')\n",
    "randomise.inputs.base_name = \"randomise_pipe_contrast_{0}\".format(current_contrast)\n",
    "randomise.inputs.design_mat = mat_file\n",
    "randomise.inputs.tcon = con_file\n",
    "randomise.inputs.args = ' --skipTo={0}'.format(current_contrast)\n",
    "randomise.inputs.num_perm = num_iterations\n",
    "randomise.inputs.demean = True\n",
    "randomise.inputs.tfce = True\n",
    "wf.connect(merge, 'merged_file', randomise, 'in_file')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "# We want to parallelize so that each contrast is processed\n",
    "        # separately\n",
    "        for current_contrast in range(1, num_contrasts + 1):\n",
    "            # use randomize to use perform permutation test for contrast\n",
    "            randomise = pe.Node(interface=fsl.Randomise(), name='fsl_randomise_{0}'.format(current_contrast))\n",
    "            wf.connect(mask, 'out_file', randomise, 'mask')\n",
    "            randomise.inputs.base_name = \"randomise_pipe_contrast_{0}\".format(current_contrast)\n",
    "            randomise.inputs.design_mat = mat_file\n",
    "            randomise.inputs.tcon = con_file\n",
    "            randomise.inputs.args = ' --skipTo={0}'.format(current_contrast)\n",
    "            randomise.inputs.num_perm = num_iterations\n",
    "            randomise.inputs.demean = True\n",
    "            randomise.inputs.tfce = True\n",
    "            wf.connect(merge, 'merged_file', randomise, 'in_file')\n",
    "\n",
    "            # threshold the resulting t corrected p file\n",
    "            thresh = pe.Node(interface=fsl.Threshold(),\n",
    "                             name='fsl_threshold_contrast_{0}'.format(current_contrast))\n",
    "            thresh.inputs.thresh = 0.95\n",
    "            wf.connect(randomise, \"t_corrected_p_files\", thresh, \"in_file\")\n",
    "\n",
    "            # binarize the result of applying the threshold to get a mask\n",
    "            thresh_bin = pe.Node(interface=fsl.maths.MathsCommand(),\n",
    "                                 name='fsl_threshold_bin_contrast_{0}'.format(current_contrast))\n",
    "            thresh_bin.inputs.args = '-bin'\n",
    "            wf.connect(thresh, \"out_file\", thresh_bin, \"in_file\")\n",
    "\n",
    "            # apply calculated mask to the statistic image\n",
    "            apply_mask = pe.Node(interface=fsl.ApplyMask(),\n",
    "                                 name='fsl_applymask_contrast_{0}'.format(current_contrast))\n",
    "            wf.connect(randomise, 'tstat_files', apply_mask, 'in_file')\n",
    "            wf.connect(thresh_bin, 'out_file', apply_mask, 'mask_file')\n",
    "\n",
    "            # cluster the results to get a report of the findings\n",
    "            cluster = pe.Node(interface=fsl.Cluster(),\n",
    "                              name='cluster_contrast_{0}'.format(current_contrast))\n",
    "            cluster.inputs.threshold = 0.0001\n",
    "            cluster.inputs.out_index_file = \"cluster_index_contrast_{0}\".format(current_contrast)\n",
    "            cluster.inputs.out_localmax_txt_file = \"lmax_contrast_{0}.txt\".format(current_contrast)\n",
    "            cluster.inputs.out_size_file = \"cluster_size_contrast_{0}\".format(current_contrast)\n",
    "            cluster.inputs.out_threshold_file = \"randomise_out_contrast_{0}\".format(current_contrast)\n",
    "            cluster.inputs.terminal_output = 'file'\n",
    "            wf.connect(apply_mask, 'out_file', cluster, 'in_file')\n",
    "\n",
    "            # attach a datasink to save the output\n",
    "            datasink = pe.Node(nio.DataSink(), name='sinker_contrast_{0}'.format(current_contrast))\n",
    "            datasink.inputs.base_directory = output_dir\n",
    "\n",
    "            wf.connect(apply_mask, 'out_file', datasink, 'output.@thresh_stat_file')\n",
    "            wf.connect(cluster, 'index_file', datasink, 'output.@index_file')\n",
    "            wf.connect(cluster, 'threshold_file', datasink, 'output.@threshold_file')\n",
    "            wf.connect(cluster, 'localmax_txt_file', datasink, 'output.@localmax_txt_file')\n",
    "            wf.connect(cluster, 'localmax_vol_file', datasink, 'output.@localmax_vol_file')\n",
    "            wf.connect(cluster, 'max_file', datasink, 'output.@max_file')\n",
    "            wf.connect(cluster, 'mean_file', datasink, 'output.@mean_file')\n",
    "            wf.connect(cluster, 'pval_file', datasink, 'output.@pval_file')\n",
    "            wf.connect(cluster, 'size_file', datasink, 'output.@size_file')\n",
    "\n",
    "          "
   ]
  }
 ],
 "metadata": {
  "anaconda-cloud": {},
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
